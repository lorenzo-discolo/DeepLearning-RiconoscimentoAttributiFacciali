{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Consegna di Progetto_ESM.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["SZimue3to0xN","RIZU73wMdFRw"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Qhg2S66Ln4kD"},"source":["# Import Librerie"]},{"cell_type":"code","metadata":{"id":"0I4Fa-LhOzul"},"source":["#@title Importa librerie\n","%reset -f\n","import numpy as np\n","import skimage.io as io\n","import matplotlib.pyplot as plt\n","import skimage.data as data\n","import scipy.ndimage as ndi\n","import tensorflow.keras\n","import pandas as pd\n","import os\n","from time import time\n","import shutil"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cmn1QiENDqjS"},"source":["#@title Funzioni Utili\n","def convert_list_to_string(org_list, seperator=' '):\n","    return seperator.join(org_list)\n","\n","def convert_string_to_list(string):\n","    li = list(string.split(\" \"))\n","    return li"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uevH0RV3oC2-"},"source":["# Caricamento Immagini in Collab"]},{"cell_type":"code","metadata":{"id":"BBhtP32LVxfT"},"source":["#@title Download Immagini\n","!wget -q -c https://www.dropbox.com/s/44695urxpk4xc2r/img_align_celeba.zip?dl=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9g5KTJEO37o"},"source":["#@title Unzip Immagini\n","!unzip -q -n img_align_celeba.zip?dl=0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2rqwqlloVn1"},"source":["# Caricamento etichette immagini"]},{"cell_type":"code","metadata":{"id":"xJ-wd8zOS1LR"},"source":["#@title Download Etichette Immagini\n","!wget -q -c https://www.dropbox.com/s/oolq770kd2wp18i/list_attr_celeba.txt?dl=0\n","fEtichette = open('list_attr_celeba.txt?dl=0',\"r\") #lettura da file \n","listaEtichette = fEtichette.readlines() \n","fEtichette.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeoU5k8JayNf"},"source":["#@title Elaborazione Etichette Immagini\n","\n","# Il file list_attr_celeba.txt contiene alla prima riga il numero di immagini prese in considerazione\n","numero_Immagini = int(listaEtichette[0])\n","\n","# Dato che devo estrarre le etichette dal file, l'informazione di tale riga\n","# risulta essere superflua, e può essere pertanto cancellata. \n","listaEtichette.pop(0)\n","attributi = listaEtichette[0]\n","\n","# Salvo in memoria anche un array di attributi, mi serve dopo\n","arrayAttributi = convert_string_to_list(attributi)\n","arrayAttributi.pop(0) #Elimino Nome_Immagine dagli attributi\n","arrayAttributi.pop(len(arrayAttributi)-1) #Elimino \\n, il carattere terminatore di stringa dall'array attributi\n","\n","# Dato che ho salvato gli attributi, cancello l'informazione di tale riga\n","listaEtichette.pop(0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylWfTP_4enCU"},"source":["#@title Crezione DataFrame per CSV\n","trainPerCSV = []\n","validPerCSV = []\n","testPerCSV = []\n","\n","trainPerCSV.append(attributi)\n","validPerCSV.append(attributi)\n","testPerCSV.append(attributi)\n","\n","# Definisco la percentuale di dati che voglio assegnare a \n","# training set, validation set e test set.\n","# % training set = splitSize*100 \n","# % validation = 10%\n","# % test set = 100 % - % training set - % validation\n","\n","# In questo caso voglio assegnare 70% training dunque:\n","splitSize = 0.7\n","\n","numeroImmaginiTrainSet = int( numero_Immagini* splitSize)\n","numeroImmaginiValidSet = int(numero_Immagini * 0.10) + 1\n","numeroImmaginiTestSet = int(numero_Immagini - numeroImmaginiTrainSet\n","                            - numeroImmaginiValidSet)\n","\n","# Costruisco i file CSV contenenti le etichette per ogni immagine\n","# I dati iniziali sono classificati con etichette -1 e 1 (classificazione binaria)\n","# Utilizzando il metodo .replace() considero l'etichetta -1 come etichetta 0\n","\n","for i in range(0,numeroImmaginiTrainSet ):\n","  line = listaEtichette[i].replace(\"-1\",\"0\")\n","  line = line.replace('  ', ' ')\n","  trainPerCSV.append(line)\n","for i in range(numeroImmaginiTrainSet, \n","               numeroImmaginiTrainSet + numeroImmaginiValidSet ):\n","  line = listaEtichette[i].replace(\"-1\",\"0\")\n","  line = line.replace('  ', ' ')\n","  validPerCSV.append(line)\n","for i in range(numeroImmaginiTrainSet + numeroImmaginiValidSet, \n","               numeroImmaginiTrainSet + numeroImmaginiValidSet \n","               + numeroImmaginiTestSet):\n","  line = listaEtichette[i].replace(\"-1\",\"0\")\n","  line = line.replace('  ', ' ')\n","  testPerCSV.append(line)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZimue3to0xN"},"source":["# Creazione CSV"]},{"cell_type":"code","metadata":{"id":"h83LHZOUiZH0"},"source":["#@title Creazione e salvataggio CSV\n","# Il comando np.savetxt salva i valori di una struttura dati in un file csv\n","np.savetxt(\"trainingSet.csv\", trainPerCSV, delimiter=' ', fmt='%s')\n","np.savetxt(\"validationSet.csv\", validPerCSV, delimiter=' ', fmt='%s')\n","np.savetxt(\"testSet.csv\", testPerCSV, delimiter=' ', fmt='%s')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RIZU73wMdFRw"},"source":["# Divisione Immagini in tre cartelle"]},{"cell_type":"code","metadata":{"id":"PYT7gA3JdJZn"},"source":["#@title Creazione cartelle per Immagini\n","try:\n","    os.mkdir('/content/training')\n","    os.mkdir('/content/validation')\n","    os.mkdir('/content/testing')\n","except OSError:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xoxbsgFpdKPi"},"source":["#@title Funzione per la divisione in cartelle\n","from shutil import move\n","def split_data(SOURCE, TRAINING, VALIDATION, TESTING):\n","    files = []\n","    print('Split Data')\n","    for filename in os.listdir(SOURCE):\n","        file = SOURCE +'/'+ filename\n","        if os.path.getsize(file) > 0:\n","            files.append(filename)\n","        else:\n","            print(filename + \" is zero length, so ignoring.\")\n","    \n","    #per creare una divisione random\n","    #shuffled_set = random.sample(files, len(files))\n","    \n","    #per una divisione ordinata \n","    files = np.sort(files)\n","\n","    training_length = numeroImmaginiTrainSet\n","    validation_length = numeroImmaginiValidSet\n","    testing_length = numeroImmaginiTestSet\n","\n","    training_set = files[0:training_length]\n","    validation_set = files[training_length:(training_length+validation_length)]\n","    testing_set = files[(training_length+validation_length):]\n","\n","    for filename in training_set:\n","        this_file = SOURCE +'/'+ filename\n","        destination = TRAINING +'/'+ filename\n","        move(this_file, destination)\n","    \n","    for filename in validation_set:\n","        this_file = SOURCE +'/'+ filename\n","        destination = VALIDATION+'/' + filename\n","        move(this_file, destination)\n","        \n","    for filename in testing_set:\n","        this_file = SOURCE +'/'+ filename\n","        destination = TESTING+'/' + filename\n","        move(this_file, destination)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgINpyknZEfN"},"source":["#@title Divisione Immagini nelle cartelle\n","source_path= '/content/img_align_celeba'\n","train_dir_path = '/content/training'\n","valid_dir_path = '/content/validation'\n","test_dir_path = '/content/testing'\n","split_data(source_path, train_dir_path, valid_dir_path, test_dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0fiUS1yoGcTD"},"source":["# Caricamento dei dati in Keras"]},{"cell_type":"code","metadata":{"id":"R8PQn0LrGiTp"},"source":["#@title Creazione di g_test, g_train e g_valid\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","size = 320 # (size,size) è la dimensione finale delle immagini\n","numeroColonne = len(arrayAttributi) + 1\n","\n","train_df = pd.read_csv('trainingSet.csv',delimiter=' ', usecols= np.arange(0,numeroColonne))\n","valid_df = pd.read_csv('validationSet.csv',delimiter=' ', usecols= np.arange(0,numeroColonne))\n","test_df = pd.read_csv('testSet.csv',delimiter=' ', usecols= np.arange(0,numeroColonne))\n","\n","# Scelgo la class mode per l'estrazione dei dati dal csv\n","# Dato che voglio considerare un insieme di colonne, da cui prelevare le etichette, scelgo raw\n","class_mode = 'raw' \n","gen_train = ImageDataGenerator(rescale = 1/255.0,\n","                               rotation_range= 10,\n","                               horizontal_flip=True,\n","                               vertical_flip=True,\n","                               width_shift_range= (size*5)//100, \n","                               height_shift_range= (size*5)//100,\n","                               zoom_range= [0.9,1.1],\n","                               dtype=np.float32)\n","trainBatch = 3 \n","g_train = gen_train.flow_from_dataframe(dataframe=train_df,directory=train_dir_path, \n","                                        target_size=(size,size),batch_size=trainBatch,\n","                                        class_mode=class_mode,\n","                                        x_col='Nome_Immagine',y_col=arrayAttributi,\n","                                        classes = arrayAttributi)\n","validBatch = 5 \n","gen_valid = ImageDataGenerator(rescale = 1/255.0,\n","                               dtype=np.float32)\n","g_valid = gen_valid.flow_from_dataframe(dataframe=valid_df,directory=valid_dir_path, \n","                                        target_size=(size,size),batch_size=validBatch,\n","                                        class_mode=class_mode,\n","                                        x_col='Nome_Immagine',y_col=arrayAttributi,\n","                                        classes = arrayAttributi)\n","testBatch = 5 \n","\n","gen_test = ImageDataGenerator(rescale = 1/255.0,\n","                              dtype=np.float32)\n","g_test = gen_test.flow_from_dataframe(dataframe=test_df,directory=test_dir_path, \n","                                      target_size=(size,size),batch_size=testBatch,\n","                                      class_mode=class_mode,shuffle=False,\n","                                      x_col='Nome_Immagine',y_col=arrayAttributi,\n","                                      classes = arrayAttributi)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2JCOHRWusF-v"},"source":["# Architettura"]},{"cell_type":"code","metadata":{"id":"pbD86NsFIkKl"},"source":["#@title Creazione rete\n","from tensorflow.keras.applications import EfficientNetB3\n","import tensorflow.keras.layers as ly\n","from tensorflow.keras.models import Sequential \n","\n","base = EfficientNetB3(weights= 'imagenet',input_shape=(size,size,3),include_top=False)\n","print(len(base.layers))\n","net = Sequential()\n","net.add(base)\n","net.add(ly.GlobalAveragePooling2D())\n","net.add(ly.Dense(40,activation='sigmoid'))\n","layer_not_train = (len(base.layers)*25)//100\n","for layer in base.layers[0:layer_not_train]:\n","  layer.trainable = False\n","net.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zhVRWEF2ygXQ"},"source":["# Addestramento"]},{"cell_type":"code","metadata":{"id":"kQZv2QbmAj7s"},"source":["linkModelli = [\n","               'https://www.dropbox.com/s/zd7mr0i1ad6hvr4/Numero_Epoche_5_LearningRate_0.30000001192092896.zip?dl=0',\n","               'https://www.dropbox.com/s/00bg895r7nznia1/Numero_Epoche_10_LearningRate_0.30000001192092896.zip?dl=0',\n","               'https://www.dropbox.com/s/04o9pp9u3am87dd/Numero_Epoche_10_LearningRate_0.0010000000474974513.zip?dl=0',\n","               'https://www.dropbox.com/s/tzn3yl5qobxyse6/Numero_Epoche_10_LearningRate_0.00001.zip?dl=0',\n","               'https://www.dropbox.com/s/srbdze8ez5o0erg/Numero_Epoche_15_LearningRate_0.0010000000474974513.zip?dl=0',\n","               'https://www.dropbox.com/s/rype1u5odc4n63e/Numero_Epoche_20_LearningRate_0.009999999776482582.zip?dl=0',\n","               'https://www.dropbox.com/s/rgjnd4j37dcra5i/Numero_Epoche_20_LearningRate_0.005.zip?dl=0'\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdTEAkRu8TaP"},"source":["#@title Funzione per ottenre il L.R. e le Epoche dal modello pre-allenato\n","def getValueFromModel(link):\n","  lr = 0\n","  epoche = 0\n","  link = link.replace('https://www.dropbox.com/s/','')\n","  index_to_remove = link.find('/') +1\n","  link = link[index_to_remove:]\n","  link = link.replace('Numero_Epoche_','')\n","  index_to_remove = link.find('_Lea')\n","  epoche = int(link[:index_to_remove])\n","  link = link.replace(str(epoche),'')\n","  link = link.replace('_LearningRate_0.','')\n","  link = link.replace('.zip?dl=0','')\n","  lr = '0.' + link\n","  lr = float(lr)\n","  return lr, epoche"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1v8r7xYvK11"},"source":["def remove_exponent(value):\n","    decial = value.split('e')\n","    ret_val = format(((float(decial[0]))*(10**int(decial[1]))), '.8f')\n","    return ret_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GtV-VH-1W9z"},"source":["#@title Scegli i valori di L.R, epoche \n","i = 0\n","\n","for link in linkModelli:\n","  i += 1\n","  lr, numEpochs = getValueFromModel(link)\n","  if lr <= 0.0001: \n","    lrt = remove_exponent(str(lr))\n","    index_to_remove = lrt.find('1') +1\n","    lrt = lrt[:index_to_remove]\n","  print('Clicca ',i,' per il modello con learning rate: ', lr, ' ed numero di epoche: ', numEpochs)\n","print('Clicca ', len(linkModelli)+1, ' per creare un nuovo modello')\n","scelta = 0\n","while (scelta == 0):\n","  try:\n","    scelta = int(input('Numero di modello scelto '))\n","  except:\n","    print('Scelta errata')\n","if scelta <= len(linkModelli):\n","  linkScelto = linkModelli[scelta-1]\n","  lr, numEpochs = getValueFromModel(linkScelto)\n","  if lr >= 0.0001:\n","    model_save_name = 'Numero_Epoche_' + str(numEpochs) + '_LearningRate_'+ str(lr)\n","  else:\n","    model_save_name = 'Numero_Epoche_' + str(numEpochs) + '_LearningRate_'+ lrt\n","  !wget -q -c {linkScelto}\n","else:\n","  numEpochs = int(input('Numero di epoche '))\n","  try:\n","    lr = float(input('Learnig rate (0.xxxxxxxx)'))\n","    model_save_name = 'Numero_Epoche_' + str(numEpochs) + '_LearningRate_'+ str(remove_exponent(lr))\n","  except:\n","    print('lr non è dell formato giusto \\n Deve essere un deciamle 0.xxxx')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9-xBh9EylKY"},"source":["#@title Compile rete\n","from tensorflow.keras.optimizers import Adam\n","optimizer = Adam(learning_rate=lr, \n","                 epsilon = 1e-08)\n","net.compile(loss='binary_crossentropy',optimizer=optimizer,\n","            metrics=['binary_accuracy'])\n","immTrainSet = numeroImmaginiTrainSet//numEpochs\n","immValidSet = numeroImmaginiValidSet//numEpochs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVPnqfb7hfWz"},"source":["#@title Carica modello preesistente se esiste\n","path_file = model_save_name+'.zip?dl=0'\n","if os.path.exists(path_file):\n","  shutil.unpack_archive(path_file,format='zip',\n","                        extract_dir=('/content/'+model_save_name))\n","  #os.remove('/content/'+path_file)\n","  net = tensorflow.keras.models.load_model(model_save_name,compile=True)\n","  net.summary()\n","else:\n","  print('rete non trovata, alleno la rete con i parametri indicati')\n","  time_before = int(time())//60\n","  history = net.fit(g_train,steps_per_epoch=immTrainSet,epochs=numEpochs,\n","                  verbose=True, validation_data=g_valid,\n","                  validation_steps=immValidSet)\n","\n","  time_after = int(time())//60\n","  deltaT = time_after - time_before # In minuti\n","  print(deltaT , ' minuti')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R_Ag8QIo39DE"},"source":["# Valutazione delle prestazioni"]},{"cell_type":"code","metadata":{"id":"pyRnppRMLcx-"},"source":["#@title Stampa caratteristiche riconosciute\n","def print_acc(matrixAccuracy,soglia = 0):\n","  print(\"Caratteristiche dell'immagine:\")\n","  for i in range(len(arrayAttributi)):\n","    if matrixAccuracy[i][1] >= soglia:\n","      if matrixAccuracy[i][2] == 1:\n","        print(matrixAccuracy[i][0] ,' => ' , matrixAccuracy[i][1], '% | expected : Ha l\\'attributo')\n","      else:\n","        print(matrixAccuracy[i][0] ,' => ' , matrixAccuracy[i][1], '% | expected : Non ha l\\'attributo')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5WiKTBM4DDF"},"source":["#@title Test con un'immagine casuale\n","import cv2\n","\n","nomeImmagine = test_df['Nome_Immagine'][np.random.randint(0,len(test_df['Nome_Immagine'])-1)]\n","path = '/content/testing/' + nomeImmagine\n","\n","test_image = np.float32(io.imread(path))\n","test_image = cv2.resize(test_image,dsize=(size,size), interpolation=cv2.INTER_CUBIC)/255\n","plt.figure();\n","plt.imshow(test_image,clim=[0,1]);\n","plt.show()\n","\n","test_image = np.reshape(test_image,(-1,size,size,3))\n","pred = net.predict(test_image)[0]\n","\n","#creo una matrice dove per ogni riga ho un attributo con la relativa accuracy dell'immagine\n","\n","matrixAccuracy = []\n","indexImage = 0\n","for i in range(len(test_df)):\n","  if test_df['Nome_Immagine'][i] == nomeImmagine:\n","    indexImage = i\n","    break\n","\n","expected = test_df.iloc[indexImage,1:41].copy()\n","for i in range(len(arrayAttributi)):\n","  matrixAccuracy.append([arrayAttributi[i],round(pred[i]*100,2),expected[i]])\n","\n","#Stampo tutti gli attributi che hanno valore maggiore di soglia%\n","soglia = 0\n","print_acc(matrixAccuracy,soglia)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqQxNcCkFZHj"},"source":["def print_scores(scores):\n","  print('La performance dei sigoli attributi è: \\n')\n","  for score in scores:\n","    print(' ',score[0],': ',score[1], '% \\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlj95DSIVr7L"},"source":["def getLayerNonAllenati(net):\n","  result = 0\n","  for layer in net.layers:\n","    if layer.trainable == False:\n","      result += 1\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aks-1AldFPXS"},"source":["#@title Calcolo dell'AUC per tutto il testSet\n","from sklearn.metrics import roc_auc_score\n","\n","# Costruisco un array di predizioni predArray\n","predArray = net.predict(g_test,verbose=True) \n","# Considerando l'array di valori corretti e predArray quello di valori stimati\n","valCorrettiTestArray = test_df.iloc[:,1:numeroColonne].copy()\n","\n","# Calcolo accuracy in termini di auc per ogni singolo attributo\n","aucArray = []\n","for i in range(1,numeroColonne):\n","  valCorrettiTestArray = test_df.iloc[:,i:i+1].copy() # Considero solo la componente dell'attributo i-esimo \n","  auc = roc_auc_score(y_true=valCorrettiTestArray,y_score=predArray[:,i-1],average='macro')\n","  #Costruisco una matrice avente due colonne: 1 per gli attributi e 1 per la relativa AUC\n","  aucArray.append([arrayAttributi[i-1], round((auc)*100,2)]) \n","\n","layer_non_allenati = getLayerNonAllenati(net)\n","print('I numero di layer della rete non allenati è: ',layer_non_allenati,'\\n')\n","\n","print_scores(aucArray)\n","\n"],"execution_count":null,"outputs":[]}]}